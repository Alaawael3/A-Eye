{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T16:20:40.649595Z",
     "iopub.status.busy": "2025-02-12T16:20:40.649196Z",
     "iopub.status.idle": "2025-02-12T16:20:40.657454Z",
     "shell.execute_reply": "2025-02-12T16:20:40.656048Z",
     "shell.execute_reply.started": "2025-02-12T16:20:40.649566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical,plot_model\n",
    "from tensorflow.keras.layers import Input,Dense,LSTM,Embedding,Dropout,add,BatchNormalization,Embedding,LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "import glob as glob\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T16:21:23.056145Z",
     "iopub.status.busy": "2025-02-12T16:21:23.055764Z",
     "iopub.status.idle": "2025-02-12T16:21:23.658636Z",
     "shell.execute_reply": "2025-02-12T16:21:23.657477Z",
     "shell.execute_reply.started": "2025-02-12T16:21:23.056110Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(cleaned_data.to_list())\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = max(len(caption.split()) for caption in cleaned_data)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T16:21:24.958134Z",
     "iopub.status.busy": "2025-02-12T16:21:24.957735Z",
     "iopub.status.idle": "2025-02-12T16:21:24.967195Z",
     "shell.execute_reply": "2025-02-12T16:21:24.966163Z",
     "shell.execute_reply.started": "2025-02-12T16:21:24.958101Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8091"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images=os.listdir(img_path)\n",
    "len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T16:21:28.047486Z",
     "iopub.status.busy": "2025-02-12T16:21:28.047028Z",
     "iopub.status.idle": "2025-02-12T16:21:28.055494Z",
     "shell.execute_reply": "2025-02-12T16:21:28.054382Z",
     "shell.execute_reply.started": "2025-02-12T16:21:28.047454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_images, test_images = train_test_split(all_images, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:07:01.773397Z",
     "iopub.status.busy": "2025-02-12T17:07:01.772970Z",
     "iopub.status.idle": "2025-02-12T17:07:05.370497Z",
     "shell.execute_reply": "2025-02-12T17:07:05.369361Z",
     "shell.execute_reply.started": "2025-02-12T17:07:01.773366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_caption, test_caption =[],[]\n",
    "for c in caption_IDs:\n",
    "    img_id,img_cap=c.split('\\t')\n",
    "    if img_id in train_images:\n",
    "        train_caption.append(c)\n",
    "    elif img_id in test_images:\n",
    "        test_caption.append(c)\n",
    "    else:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3_model=InceptionV3(weights='imagenet',include_top=False,input_shape=(299, 299, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T16:27:20.184785Z",
     "iopub.status.busy": "2025-02-12T16:27:20.184478Z",
     "iopub.status.idle": "2025-02-12T16:27:20.206984Z",
     "shell.execute_reply": "2025-02-12T16:27:20.205977Z",
     "shell.execute_reply.started": "2025-02-12T16:27:20.184758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The second-to-last layer typically contains high-level features learned by the model.\n",
    "inceptionV3_model = Model(inputs=inceptionV3_model.inputs, outputs=inceptionV3_model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T16:27:20.653997Z",
     "iopub.status.busy": "2025-02-12T16:27:20.653628Z",
     "iopub.status.idle": "2025-02-12T16:54:57.892415Z",
     "shell.execute_reply": "2025-02-12T16:54:57.891096Z",
     "shell.execute_reply.started": "2025-02-12T16:27:20.653966Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5dcd54936d4861951d4220eb663a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8091 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = {}\n",
    "for image in tqdm(data['image'].unique().tolist()):\n",
    "    img = load_img(os.path.join(img_path, image), target_size=(299, 299))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    feature = inceptionV3_model.predict(img, verbose=0)\n",
    "    features[image] = feature.flatten()  # Flatten the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T16:58:44.568555Z",
     "iopub.status.busy": "2025-02-12T16:58:44.568200Z",
     "iopub.status.idle": "2025-02-12T16:58:45.952584Z",
     "shell.execute_reply": "2025-02-12T16:58:45.951592Z",
     "shell.execute_reply.started": "2025-02-12T16:58:44.568530Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_image_features, test_image_features = {}, {} # A Dictionary to store image features with their corresponding IDs       \n",
    "for id_ in features:\n",
    "    if id_ in train_images:\n",
    "        train_image_features[id_] = features[id_].flatten()  # Flattening the features    \n",
    "    elif id_ in test_images:\n",
    "        test_image_features[id_] = features[id_].flatten()  # Flattening the features\n",
    "    else:\n",
    "        print('Unknown image ID !')\n",
    "# get the feature matrix for every image and store them in these dictionaries train_image_features, test_image_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:07:38.838943Z",
     "iopub.status.busy": "2025-02-12T17:07:38.838609Z",
     "iopub.status.idle": "2025-02-12T17:07:38.846795Z",
     "shell.execute_reply": "2025-02-12T17:07:38.845680Z",
     "shell.execute_reply.started": "2025-02-12T17:07:38.838918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def data_generator(captions, image_features, tokenizer, max_caption_len, batch_size):\n",
    "    num_samples = len(captions)\n",
    "    image_ids = list(image_features.keys())\n",
    "    \n",
    "    while True:\n",
    "        np.random.shuffle(image_ids)\n",
    "        \n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            x_images, x_captions, y = [], [], []\n",
    "            for caption in captions[start:end]:\n",
    "                image_id = caption.split('\\t')[0]  # Assuming your DataFrame has 'image' column\n",
    "                caption_text = caption.split('\\t')[1]  # Assuming 'cleaned_caption' is the processed caption text column\n",
    "                \n",
    "                seq = tokenizer.texts_to_sequences([caption_text])[0]\n",
    "                \n",
    "                for i in range(1, len(seq)):\n",
    "                    in_seq, out_word = seq[:i], seq[i]\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_caption_len)[0]\n",
    "                    out_word = to_categorical([out_word], num_classes=vocab_size)[0]\n",
    "                    \n",
    "                    x_images.append(image_features[image_id])  # Already flattened\n",
    "                    x_captions.append(in_seq)\n",
    "                    y.append(out_word)\n",
    "            \n",
    "            yield (np.array(x_images), np.array(x_captions)), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:07:39.179534Z",
     "iopub.status.busy": "2025-02-12T17:07:39.179202Z",
     "iopub.status.idle": "2025-02-12T17:07:39.216256Z",
     "shell.execute_reply": "2025-02-12T17:07:39.215395Z",
     "shell.execute_reply.started": "2025-02-12T17:07:39.179508Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_captions_len=max(len(line.split()) for line in cleaned_data)+1\n",
    "max_captions_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:07:39.711322Z",
     "iopub.status.busy": "2025-02-12T17:07:39.710936Z",
     "iopub.status.idle": "2025-02-12T17:07:39.717339Z",
     "shell.execute_reply": "2025-02-12T17:07:39.716390Z",
     "shell.execute_reply.started": "2025-02-12T17:07:39.711292Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12288"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_output_dim = inceptionV3_model.output_shape[1] * inceptionV3_model.output_shape[2] * inceptionV3_model.output_shape[3]\n",
    "cnn_output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:42:36.024802Z",
     "iopub.status.busy": "2025-02-12T17:42:36.024405Z",
     "iopub.status.idle": "2025-02-12T17:42:36.029710Z",
     "shell.execute_reply": "2025-02-12T17:42:36.028554Z",
     "shell.execute_reply.started": "2025-02-12T17:42:36.024772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_train=64\n",
    "batch_test=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T17:07:41.598456Z",
     "iopub.status.busy": "2025-02-12T17:07:41.598092Z",
     "iopub.status.idle": "2025-02-12T17:07:41.602813Z",
     "shell.execute_reply": "2025-02-12T17:07:41.601603Z",
     "shell.execute_reply.started": "2025-02-12T17:07:41.598430Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data_generator = data_generator(train_caption, train_image_features, tokenizer, max_captions_len, batch_train)\n",
    "test_data_generator = data_generator(test_caption, test_image_features, tokenizer, max_captions_len, batch_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T19:08:31.963026Z",
     "iopub.status.busy": "2025-02-12T19:08:31.962639Z",
     "iopub.status.idle": "2025-02-12T19:08:31.969807Z",
     "shell.execute_reply": "2025-02-12T19:08:31.968633Z",
     "shell.execute_reply.started": "2025-02-12T19:08:31.962997Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, max_caption_len, cnn_output_dim):\n",
    "    # Encoder\n",
    "    Input_image = Input(shape=(cnn_output_dim,), name='Feature_Input')  # Flattened shape\n",
    "    x = BatchNormalization()(Input_image)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Decoder\n",
    "    Input_cation = Input(shape=(max_caption_len,), name='Caption_Input')\n",
    "    y = Embedding(input_dim=vocab_size, output_dim=256, mask_zero=True)(Input_cation)\n",
    "    y = LSTM(256)(y)\n",
    "    \n",
    "    # Output\n",
    "    decoder = add([x, y])\n",
    "    decoder = Dense(256, activation='relu')(decoder)\n",
    "    output = Dense(vocab_size, activation='softmax', name='output_layer')(decoder)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=[Input_image, Input_cation], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T19:08:32.462959Z",
     "iopub.status.busy": "2025-02-12T19:08:32.462590Z",
     "iopub.status.idle": "2025-02-12T19:08:32.635261Z",
     "shell.execute_reply": "2025-02-12T19:08:32.634164Z",
     "shell.execute_reply.started": "2025-02-12T19:08:32.462929Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Feature_Input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12288</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_202   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12288</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">49,152</span> │ Feature_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ Caption_Input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,145,984</span> │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,244,096</span> │ Caption_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ not_equal_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Caption_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_203   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                           │                        │                │ not_equal_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
       "│                           │                        │                │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8766</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,252,862</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Feature_Input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12288\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_202   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12288\u001b[0m)          │         \u001b[38;5;34m49,152\u001b[0m │ Feature_Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ Caption_Input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │      \u001b[38;5;34m3,145,984\u001b[0m │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │      \u001b[38;5;34m2,244,096\u001b[0m │ Caption_Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ not_equal_7 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ Caption_Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_203   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │          \u001b[38;5;34m1,024\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m525,312\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                           │                        │                │ not_equal_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
       "│                           │                        │                │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m65,792\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8766\u001b[0m)           │      \u001b[38;5;34m2,252,862\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,284,222</span> (31.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,284,222\u001b[0m (31.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,259,134</span> (31.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,259,134\u001b[0m (31.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,088</span> (98.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m25,088\u001b[0m (98.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=build_model(vocab_size,max_captions_len,cnn_output_dim)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T19:08:32.819096Z",
     "iopub.status.busy": "2025-02-12T19:08:32.818761Z",
     "iopub.status.idle": "2025-02-12T19:08:32.830112Z",
     "shell.execute_reply": "2025-02-12T19:08:32.828869Z",
     "shell.execute_reply.started": "2025-02-12T19:08:32.819031Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.1, clipnorm=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-12T19:08:32.831918Z",
     "iopub.status.busy": "2025-02-12T19:08:32.831513Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 5s/step - loss: 6.4640 - val_loss: 4.9123 - learning_rate: 0.0549\n",
      "Epoch 2/15\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 5s/step - loss: 4.8345 - val_loss: 4.7899 - learning_rate: 0.0301\n",
      "Epoch 3/15\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 5s/step - loss: 4.4630 - val_loss: 4.5336 - learning_rate: 0.0165\n",
      "Epoch 4/15\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 5s/step - loss: 4.3137 - val_loss: 4.4567 - learning_rate: 0.0091\n",
      "Epoch 5/15\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 5s/step - loss: 4.2220 - val_loss: 4.4484 - learning_rate: 0.0050\n",
      "Epoch 6/15\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 5s/step - loss: 4.1722 - val_loss: 4.3680 - learning_rate: 0.0027\n",
      "Epoch 7/15\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m534s\u001b[0m 5s/step - loss: 4.1616 - val_loss: 4.3858 - learning_rate: 0.0015\n",
      "Epoch 8/15\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 5s/step - loss: 4.1204 - val_loss: 4.3420 - learning_rate: 8.2297e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m107/107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 5s/step - loss: 4.0383 - val_loss: 4.4158 - learning_rate: 4.5166e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m 25/107\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:45\u001b[0m 5s/step - loss: 4.0081"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    return float(lr * tf.math.exp(-0.6))\n",
    "\n",
    "    \n",
    "lr_schedul = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "steps_per_epoch = len(train) // batch_train\n",
    "validation_steps = len(test) // batch_test\n",
    "\n",
    "history = model.fit(\n",
    "    train_data_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=test_data_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping, lr_schedul]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], color='green', linestyle='-', marker='o', markersize=5, label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], color='red', linestyle='--', marker='x', markersize=5, label='Validation Loss')\n",
    "\n",
    "plt.title('Model Loss Over Epochs', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.legend(loc='upper left', fontsize=12)\n",
    "\n",
    "plt.xlim(0, len(history.history['loss']) - 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 623289,
     "sourceId": 1111676,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
